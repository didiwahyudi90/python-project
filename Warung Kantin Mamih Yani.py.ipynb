import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.impute import SimpleImputer
from joblib import dump, load
import os
import pickle



# Load data
data = pd.read_csv('C:/Users/ASUS/wadidaw/data/warung kantin mamih yani.csv')

# Preprocess data
# Drop unnecessary columns
data = data.drop(['Tanggal_order', 'Participant_ID'], axis=1)




# label encoding kolom jenis kelamin
data['Jenis_kelamin'] = data['Jenis_kelamin'].map({'Pria':0, 'Perempuan':1})

# label encoding kolom kewarganegaraan
data['Kewarganegaraan'] = data['Kewarganegaraan'].map({'Aljazair':0,
                               'Australia':1,
                               'Indonesia':2,
                               'Inggris':3,
                               'Jepang':4,
                               'Kanada':5,
                               'Korean':6,
                               'Maladewa':7,
                               'Malaysia':8,
                               'Mauritinia':9,
                               'Nigeria':10,
                               'Singapore':11,
                               'Tanzania':12,
                               'Tiongkok':13,
                               'Yaman':14})
# label encoding kolom Grup_umur
data['Grup_umur'] = data['Grup_umur'].map({'Remaja':0, 'Dewasa':1,'Orang Tua':2})

# label encoding kolom Jenis Makanan
data['Jenis_Makanan'] = data['Jenis_Makanan'].map({'Makanan_Tradisional':0, 'Makanan_Barat':1})

# label encoding kolom Minuman
data['Minuman'] = data['Minuman'].map({'Jus Segar':0, 'Minuman Bersoda':1})

# label encoding kolom Dessert
data['Dessert'] = data['Dessert'].map({'Tidak':0, 'Ya':1,'Mungkin':2})


# Create an imputer object
imputer = SimpleImputer(strategy='mean')

# Fit the imputer to the data and transform it
X = imputer.fit_transform(X)  # Apply the imputer to fill missing values in X

# Feature selection
# Select K best features
X = data.drop(['Jenis_kelamin', 'Grup_umur', 'Jenis_Makanan', 'Minuman'], axis=1)
y = data['Dessert']

selector = SelectKBest(chi2, k='all')
X_new = selector.fit_transform(X, y)


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train KNN model
knn = KNeighborsClassifier()

# Hyperparameter tuning
param_grid = {
    'n_neighbors': [3, 5, 7],
    'weights': ['uniform', 'distance']
}

grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

best_knn = grid_search.best_estimator_
y_pred_knn = best_knn.predict(X_test)

# Evaluate KNN model
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print("Akurasi KNN:", accuracy_knn)
print(classification_report(y_test, y_pred_knn))
print(confusion_matrix(y_test, y_pred_knn))

# Train SVC model
svc = SVC()

# Hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']
}

grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

best_svc = grid_search.best_estimator_
y_pred_svc = best_svc.predict(X_test)

# Evaluate SVC model
accuracy_svc = accuracy_score(y_test, y_pred_svc)
print("Akurasi SVC:", accuracy_svc)
print(classification_report(y_test, y_pred_svc))
print(confusion_matrix(y_test, y_pred_svc))

try:
    best_model = joblib.load('classifier.pkl')
except Exception as e:
    print("Error loading model:", e)
    # Handle the error as needed


# Save the best model
if accuracy_knn > accuracy_svc:
    best_model = best_knn
else:
    best_model = best_svc

joblib.dump(best_model, 'classifier.pkl')
print("Model saved successfully!")  # Confirm that the model was saved

# Load the best model
best_model = joblib.load('classifier.pkl')
